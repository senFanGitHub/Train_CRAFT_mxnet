{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import nd, gluon\n",
    "from mxnet.gluon import data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import datautils\n",
    "import json\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import math\n",
    "import mxnet as mx\n",
    "import argparse, time, logging, random, math\n",
    "from mxnet import autograd as ag\n",
    "from mxnet_CharDet import CharDet\n",
    "from post_process import normalizeMeanVariance,cvt2HeatmapImg,getDetBoxes_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CharDet_Data(data.Dataset):\n",
    "    \"\"\"\n",
    "    1.将带有字符级标注的数据准备成三元组（原图，字符热力图，字符连接区域热力图），热力图的形式可自定义调试，满足中间置信度高，四周低就行了。\n",
    "    判断热力图制作是否合理的粗略标准是：经过特定的后处理能还原回文本框。\n",
    "    2.目前开源的字符级标准数据有2个：ICDAR的ReCTs 和人工合成数据SynthText，该类即针对这两个数据集准备三元组，且SynthText太多，训练时不必都用。\n",
    "    3.验证流程时，可以只用ReCTs，SynthText太大了。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Synth_gt, norm=True, have_Synth_img=False, ReCTS_img_root= '/data3/fansen/CVProject/text-detection/DataSets/ReCTs/img', random_rote_rate=None,\n",
    "                 image_size=(3, 640, 640), down_rate=2, transform=None,img_num=20000):\n",
    "        \n",
    "        self.have_Synth_img=have_Synth_img\n",
    "        if self.have_Synth_img:\n",
    "            Synth_img_root = \"/data3/fansen/CVProject/text-detection/DataSets/SynthText80W/SynthText\"\n",
    "            self.Synth_img_root = Synth_img_root\n",
    "            start_index = random.randint(1,200000)\n",
    "            self.gt = {}\n",
    "            self.gt[\"txt\"] = Synth_gt[\"txt\"][0][:-1][start_index:start_index+img_num]\n",
    "            self.gt[\"imnames\"] = Synth_gt[\"imnames\"][0][start_index:start_index+img_num]\n",
    "            self.gt[\"charBB\"] = Synth_gt[\"charBB\"][0][start_index:start_index+img_num]\n",
    "            self.gt[\"wordBB\"] = Synth_gt[\"wordBB\"][0][start_index:start_index+img_num]\n",
    "            \n",
    "            \n",
    "\n",
    "        self.image_list = [os.path.join(ReCTS_img_root, i) for i in os.listdir(ReCTS_img_root)]\n",
    "        self.label_list = [(i.replace('jpg', 'json')).replace('img', 'gt') for i in self.image_list]\n",
    "\n",
    "        self.norm = norm\n",
    "        self.image_size = image_size\n",
    "        self.down_rate = down_rate\n",
    "        self.transform = transform\n",
    "        self.random_rote_rate = random_rote_rate\n",
    "\n",
    "        ky = cv2.getGaussianKernel(40, int(40 * 0.33))\n",
    "        kx = cv2.getGaussianKernel(40, int(40 * 0.33))\n",
    "        MAP = np.multiply(ky, np.transpose(kx))\n",
    "        norMap = np.multiply(MAP, 1 / np.max(MAP))\n",
    "        box = np.float32([[0, 0], [39, 0], [39, 39], [0, 39]])\n",
    "        self.heatmap_loc = box\n",
    "        self.heatmap = norMap\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.have_Synth_img:\n",
    "            return len(self.label_list) + self.gt[\"txt\"].shape[0]\n",
    "        else:\n",
    "            return len(self.label_list)\n",
    "\n",
    "    def normalizeMeanVariance(self, in_img, mean=(0.406, 0.456, 0.485), variance=(0.225, 0.224, 0.229)):\n",
    "        # RGB order mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)\n",
    "        # BGR order mean=(0.406, 0.456, 0.485), variance=(0.225, 0.224, 0.229)\n",
    "        img = in_img.copy().astype(np.float32)\n",
    "  \n",
    "\n",
    "        img -= np.array([mean[0] * 255.0, mean[1] * 255.0, mean[2] * 255.0], dtype=np.float32)\n",
    "        img /= np.array([variance[0] * 255.0, variance[1] * 255.0, variance[2] * 255.0], dtype=np.float32)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def find_min_rectangle(self, points):\n",
    "\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = points\n",
    "        lt_x = min(x1, x2, x3, x4)\n",
    "        lt_y = min(y1, y2, y3, y4)\n",
    "        rd_x = max(x1, x2, x3, x4)\n",
    "        rd_y = max(y1, y2, y3, y4)\n",
    "\n",
    "        return np.float32([[lt_x, lt_y], [rd_x, lt_y], [rd_x, rd_y], [lt_x, rd_y]]), int(rd_x - lt_x), int(rd_y - lt_y)\n",
    "\n",
    "    def syn_resize(self, image, char_label, word_laebl):\n",
    "        h, w, c = image.shape\n",
    "        img = np.zeros(self.image_size)\n",
    "        rate = self.image_size[2] / self.image_size[1]\n",
    "        rate_pic = w / h\n",
    "\n",
    "        if rate_pic > rate:\n",
    "            resize_h = int(self.image_size[2] / rate_pic)\n",
    "            image = cv2.resize(image, (self.image_size[2], resize_h))\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            img[:, :resize_h, :] = image\n",
    "            char_label = char_label * (resize_h / h)\n",
    "            word_laebl = word_laebl * (resize_h / h)\n",
    "        else:\n",
    "            resize_w = int(rate_pic * self.image_size[1])\n",
    "            image = cv2.resize(image, (resize_w, self.image_size[1]))\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            img[:, :, :resize_w] = np.array(image)\n",
    "            char_label = char_label * (resize_w / w)\n",
    "            word_laebl = word_laebl * (resize_w / w)\n",
    "\n",
    "        return img, char_label, word_laebl\n",
    "\n",
    "    def rects_resize(self, image, lines_loc, line_boxes):\n",
    "        h, w, c = image.shape\n",
    "        img = np.zeros(self.image_size)\n",
    "        rate = self.image_size[2] / self.image_size[1]\n",
    "        rate_pic = w / h\n",
    "\n",
    "        if rate_pic > rate:\n",
    "            resize_h = int(self.image_size[2] / rate_pic)\n",
    "            image = cv2.resize(image, (self.image_size[2], resize_h))\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            img[:, :resize_h, :] = image\n",
    "\n",
    "            lines_loc = lines_loc * (resize_h / h)  # / self.down_rate\n",
    "            for i in range(len(line_boxes)):\n",
    "                for j in range(len(line_boxes[i])):\n",
    "                    for k in range(len(line_boxes[i][j])):\n",
    "                        line_boxes[i][j][k] = line_boxes[i][j][k] * (resize_h / h)  # / self.down_rate\n",
    "\n",
    "        else:\n",
    "\n",
    "            resize_w = int(rate_pic * self.image_size[1])\n",
    "            image = cv2.resize(image, (resize_w, self.image_size[1]))\n",
    "            image = image.transpose((2, 0, 1))\n",
    "            img[:, :, :resize_w] = image\n",
    "            lines_loc = lines_loc * (resize_w / w)  # / self.down_rate\n",
    "            for i in range(len(line_boxes)):\n",
    "                for j in range(len(line_boxes[i])):\n",
    "                    for k in range(len(line_boxes[i][j])):\n",
    "                        line_boxes[i][j][k] = line_boxes[i][j][k] * (resize_w / w)  # / self.down_rate\n",
    "\n",
    "        return img, lines_loc, line_boxes\n",
    "\n",
    "    def get_SynthText_item(self, idx):\n",
    "        img_name = self.gt[\"imnames\"][idx][0]\n",
    "        image = cv2.imread(os.path.join(self.Synth_img_root, img_name))\n",
    "\n",
    "        if self.norm:\n",
    "            image = self.normalizeMeanVariance(image)\n",
    "\n",
    "        char_label = self.gt[\"charBB\"][idx].transpose(2, 1, 0)\n",
    "\n",
    "        if len(self.gt[\"wordBB\"][idx].shape) == 3:\n",
    "            word_laebl = self.gt[\"wordBB\"][idx].transpose(2, 1, 0)\n",
    "        else:\n",
    "            word_laebl = self.gt[\"wordBB\"][idx].transpose(1, 0)[np.newaxis, :]\n",
    "        txt_label = self.gt[\"txt\"][idx]\n",
    "\n",
    "        debug_size = image.shape\n",
    "        img, char_label, word_laebl = self.syn_resize(image, char_label, word_laebl)\n",
    "\n",
    "        if self.random_rote_rate:\n",
    "            angel = random.randint(0 - self.random_rote_rate, self.random_rote_rate)\n",
    "            img, M = datautils.rotate(angel, img)\n",
    "\n",
    "        char_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "        aff_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "\n",
    "        line_boxes = []\n",
    "        char_index = 0\n",
    "        word_index = 0\n",
    "        for txt in txt_label:\n",
    "            for strings in txt.split(\"\\n\"):\n",
    "                for string in strings.split(\" \"):\n",
    "                    if string == \"\":\n",
    "                        continue\n",
    "                    char_boxes = []\n",
    "                    for char in string:\n",
    "                        x0, y0 = char_label[char_index][0]\n",
    "                        x1, y1 = char_label[char_index][1]\n",
    "                        x2, y2 = char_label[char_index][2]\n",
    "                        x3, y3 = char_label[char_index][3]\n",
    "\n",
    "                        #                         if self.random_rote_rate:\n",
    "                        #                             x0, y0 = datautils.rotate_point(M, x0, y0)\n",
    "                        #                             x1, y1 = datautils.rotate_point(M, x1, y1)\n",
    "                        #                             x2, y2 = datautils.rotate_point(M, x2, y2)\n",
    "                        #                             x3, y3 = datautils.rotate_point(M, x3, y3)\n",
    "\n",
    "                        x0, y0, x1, y1, x2, y2, x3, y3 = int(round(x0)), int(round(y0)), int(round(x1)), int(\n",
    "                            round(y1)), int(round(x2)), int(round(y2)), int(round(x3)), int(round(y3))\n",
    "                        char_boxes.append([x0, y0, x1, y1, x2, y2, x3, y3])\n",
    "                        min_rect, min_rect_w, min_rect_h = self.find_min_rectangle([x0, y0, x1, y1, x2, y2, x3, y3])\n",
    "\n",
    "                        pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                        top_l_x, top_l_y = min_rect[0]\n",
    "                        pts = pts - [top_l_x, top_l_y]\n",
    "                        M = cv2.getPerspectiveTransform(self.heatmap_loc, pts)\n",
    "                        res = cv2.warpPerspective(self.heatmap, M, (min_rect_w, min_rect_h))\n",
    "\n",
    "                        min_x = min(x0, x1, x2, x3)\n",
    "                        min_y = min(y0, y1, y2, y3)\n",
    "\n",
    "                        if min_x >= self.image_size[2]:\n",
    "                            # nima gt框标注存有些整个在图像只有\n",
    "                            continue\n",
    "                        gh, gw = res.shape\n",
    "                        for th in range(gh):\n",
    "                            for tw in range(gw):\n",
    "                                try:\n",
    "                                    char_gt[min_y + th, min_x + tw] = max(char_gt[min_y + th, min_x + tw], res[th, tw])\n",
    "                                except:\n",
    "                                    ## 本来标注就有问题，gt框存在越界情况，直接舍弃越界部分\n",
    "                                    pass\n",
    "\n",
    "                        char_index += 1\n",
    "                    word_index += 1\n",
    "                    line_boxes.append(char_boxes)\n",
    "        affine_boxes = []\n",
    "\n",
    "        for char_boxes in line_boxes:\n",
    "            affine_boxes.extend(datautils.create_affine_boxes(char_boxes))\n",
    "            for points in affine_boxes:\n",
    "                x0, y0, x1, y1, x2, y2, x3, y3 = points[0], points[1], points[2], points[3], points[4], points[5], \\\n",
    "                                                 points[6], points[7]\n",
    "                #                 box, deta_x, deta_y = self.find_min_rectangle(points)\n",
    "                min_rect, min_rect_w, min_rect_h = self.find_min_rectangle(points)\n",
    "\n",
    "                pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                top_l_x, top_l_y = min_rect[0]\n",
    "                pts = pts - [top_l_x, top_l_y]\n",
    "                M = cv2.getPerspectiveTransform(self.heatmap_loc, pts)\n",
    "                res = cv2.warpPerspective(self.heatmap, M, (min_rect_w, min_rect_h))\n",
    "\n",
    "                min_x = min(x0, x1, x2, x3)\n",
    "                min_y = min(y0, y1, y2, y3)\n",
    "\n",
    "                if min_x >= self.image_size[2]:\n",
    "                    #                     print(char_boxes)\n",
    "                    continue\n",
    "                gh, gw = res.shape\n",
    "                for th in range(gh):\n",
    "                    for tw in range(gw):\n",
    "                        try:\n",
    "                            aff_gt[min_y + th, min_x + tw] = max(aff_gt[min_y + th, min_x + tw], res[th, tw])\n",
    "                        ## 按理来说根据link框的定义，不会存在越界的情况，但是TM的GT有的框整个都在图片外，导致link框也会越界\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        char_gt = cv2.resize(char_gt,\n",
    "                             (int(self.image_size[2] / self.down_rate), int(self.image_size[1] / self.down_rate)))\n",
    "        aff_gt = cv2.resize(aff_gt,\n",
    "                            (int(self.image_size[2] / self.down_rate), int(self.image_size[1] / self.down_rate)))\n",
    "\n",
    "        img = nd.array(img)\n",
    "        char_gt = nd.array(char_gt)\n",
    "        aff_gt = nd.array(aff_gt)\n",
    "        sample = (img, char_gt, aff_gt)\n",
    "        return sample\n",
    "\n",
    "    def get_ReCTS_item(self, idx):\n",
    "        image_path = self.image_list[idx]\n",
    "        label_path = self.label_list[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if self.norm:\n",
    "            image = self.normalizeMeanVariance(image)\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            label_json = json.load(f)\n",
    "\n",
    "        lines_loc = []\n",
    "        chars_loc = []\n",
    "        lines_boxes = []\n",
    "        char_num = 0\n",
    "        total_char_num = len(label_json[\"chars\"])\n",
    "        char_index = list(range(total_char_num))\n",
    "        for line in label_json[\"lines\"]:\n",
    "            line_label = line[\"transcription\"]\n",
    "            #             if len(line_label) == 1:\n",
    "            #                 lines_boxes.append([line[\"points\"]])\n",
    "            if line_label == \"###\":\n",
    "                #                 neg_lines.append(line[\"points\"])\n",
    "                #                 print(line[\"points\"])\n",
    "                contours = np.array(line[\"points\"])\n",
    "                contours = contours.astype('int32')\n",
    "                contours = contours.reshape((4, 2))\n",
    "                cv2.drawContours(image, [contours], -1, (0, 0, 0), -1)\n",
    "                continue\n",
    "            if line_label != \"###\":\n",
    "                lines_loc.append(line[\"points\"])\n",
    "            line_boxes = []\n",
    "\n",
    "            for c in line_label:\n",
    "                for char_num in char_index:\n",
    "                    c_label = label_json[\"chars\"][char_num][\"transcription\"]\n",
    "                    if c_label == c:\n",
    "                        if label_json[\"chars\"][char_num][\"points\"] != [-1, -1, -1, -1, -1, -1, -1, -1]:\n",
    "                            line_boxes.append(label_json[\"chars\"][char_num][\"points\"])\n",
    "\n",
    "                        char_index.remove(char_num)\n",
    "                        break\n",
    "\n",
    "            lines_boxes.append(line_boxes)\n",
    "\n",
    "        lines_loc = np.array(lines_loc)\n",
    "        img, lines_loc, lines_boxes = self.rects_resize(image, lines_loc, lines_boxes)\n",
    "\n",
    "        if self.random_rote_rate:\n",
    "            angel = random.randint(0 - self.random_rote_rate, self.random_rote_rate)\n",
    "            img, M = datautils.rotate(angel, img)\n",
    "\n",
    "        char_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "        aff_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "\n",
    "        for line_box in lines_boxes:\n",
    "            for box in line_box:\n",
    "                x0, y0, x1, y1, x2, y2, x3, y3 = box\n",
    "                if self.random_rote_rate:\n",
    "                    x0, y0 = datautils.rotate_point(M, x0, y0)\n",
    "                    x1, y1 = datautils.rotate_point(M, x1, y1)\n",
    "                    x2, y2 = datautils.rotate_point(M, x2, y2)\n",
    "                    x3, y3 = datautils.rotate_point(M, x3, y3)\n",
    "                x0, y0, x1, y1, x2, y2, x3, y3 = int(round(x0)), int(round(y0)), int(round(x1)), int(\n",
    "                    round(y1)), int(round(x2)), int(round(y2)), int(round(x3)), int(round(y3))\n",
    "                pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                M = cv2.getPerspectiveTransform(self.heatmap_loc, pts)\n",
    "                res = cv2.warpPerspective(self.heatmap, M, (int(self.image_size[2]), int(self.image_size[1])))\n",
    "                sum_ = np.concatenate((char_gt[np.newaxis, :], res[np.newaxis, :]), axis=0)\n",
    "                char_gt = np.max(sum_, axis=0)  ##避免标注字符框的重叠\n",
    "\n",
    "            affine_boxes = datautils.create_affine_boxes(line_box)\n",
    "            for points in affine_boxes:\n",
    "                x0, y0, x1, y1, x2, y2, x3, y3 = points[0], points[1], points[2], points[3], points[4], points[5], \\\n",
    "                                                 points[6], points[7]\n",
    "                pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                M = cv2.getPerspectiveTransform(self.heatmap_loc, pts)\n",
    "                res = cv2.warpPerspective(self.heatmap, M, (int(self.image_size[2]), int(self.image_size[1])))\n",
    "                sum_ = np.concatenate((aff_gt[np.newaxis, :], res[np.newaxis, :]), axis=0)\n",
    "                aff_gt = np.max(sum_, axis=0)  ##避免标注字符框的重叠\n",
    "\n",
    "        char_gt = cv2.resize(char_gt,\n",
    "                             (int(self.image_size[2] / self.down_rate), int(self.image_size[1] / self.down_rate)))\n",
    "        aff_gt = cv2.resize(aff_gt,\n",
    "                            (int(self.image_size[2] / self.down_rate), int(self.image_size[1] / self.down_rate)))\n",
    "\n",
    "        img = nd.array(img)\n",
    "        char_gt = nd.array(char_gt)\n",
    "        aff_gt = nd.array(aff_gt)\n",
    "        sample = (img, char_gt, aff_gt)\n",
    "        return sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.have_Synth_img:\n",
    "            if idx < len(self.label_list):\n",
    "                sample = self.get_ReCTS_item(idx)\n",
    "            else:\n",
    "                syn_idx = idx - len(self.label_list)\n",
    "                sample = self.get_SynthText_item(syn_idx)\n",
    "\n",
    "            return sample\n",
    "        else:\n",
    "            return self.get_ReCTS_item(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     19,
     30,
     39
    ]
   },
   "outputs": [],
   "source": [
    "class Train_Char_Det():\n",
    "    def __init__(self,Synth_gt,train=True,pretrained ='Models/ReCTS.params', ReCTS_root='/data3/ml/fansen/162_CV/Train_ocr_det/ReCTs/img',max_update=200000,batch=3):\n",
    "        self.ctx=mx.gpu()\n",
    "        self.pretrained = pretrained\n",
    "        self.batch = batch\n",
    "        self.max_update=max_update\n",
    "        self.train=train\n",
    "        self.ReCTS_root=ReCTS_root\n",
    "        self._build_model()\n",
    "        if self.train:\n",
    "            assert(self.ctx==mx.gpu())\n",
    "            try:\n",
    "                self.gt_file = scio.loadmat(Synth_gt)\n",
    "            except:\n",
    "                self.gt_file=None\n",
    "            \n",
    "            self._build_data()\n",
    "            self._build_opt()\n",
    "        \n",
    "    def _build_data(self):\n",
    "\n",
    "        H = random.randint(8,12)\n",
    "        self.data_set = CharDet_Data(Synth_gt=self.gt_file,image_size=(3, 48*H, 64*H),ReCTS_img_root=self.ReCTS_root)\n",
    "        self.data_iter = data.DataLoader(self.data_set , batch_size=self.batch, shuffle=True,last_batch=\"discard\", num_workers = 3)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \n",
    "        self.net = CharDet(train_init=False)\n",
    "        self.net.load_parameters(self.pretrained, allow_missing=False, ignore_extra=False,ctx=self.ctx)\n",
    "        \n",
    "    def _build_opt(self):\n",
    "        self.epochos = self.max_update//len(self.data_iter )\n",
    "        \n",
    "        schedule = mx.lr_scheduler.CosineScheduler(base_lr=0.03,final_lr=0.0001,max_update=self.max_update,warmup_steps=500)\n",
    "        sgd_optimizer = mx.optimizer.SGD(learning_rate=0.03,momentum=0.9,wd=0.0005 ,lr_scheduler=schedule)\n",
    "        \n",
    "        self.trainer = gluon.Trainer(self.net.collect_params(),optimizer=sgd_optimizer)\n",
    "        self.loss_MSE = gluon.loss.L2Loss()\n",
    "\n",
    "    def check_iter(self):\n",
    "        assert(self.train)\n",
    "        if not os.path.isdir(\"check_iter\"):\n",
    "            os.mkdir('check_iter')\n",
    "        for i,batch_data in enumerate(self.data_iter):\n",
    "\n",
    "            batch_npimg=batch_data[0].asnumpy()\n",
    "            batch_char=batch_data[1].asnumpy()\n",
    "            batch_link=batch_data[2].asnumpy()\n",
    "\n",
    "            img =batch_npimg[0]\n",
    "            img=np.transpose(img,(1,2,0))\n",
    "\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "#            \n",
    "            \n",
    "            mean=(0.406, 0.456, 0.485)\n",
    "            variance=(0.225, 0.224, 0.229)\n",
    "            img =  img*np.array([variance[0] * 255.0, variance[1] * 255.0, variance[2] * 255.0], dtype=np.float32)\n",
    "            img = img + np.array([mean[0] * 255.0, mean[1] * 255.0, mean[2] * 255.0], dtype=np.float32)\n",
    "#             img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "            img=img.astype('uint8')\n",
    "            cv2.imwrite('check_iter/src.jpg',img)\n",
    "\n",
    "            char_gt_score =  batch_char[0]\n",
    "            link_gt_score = batch_link[0]\n",
    "\n",
    "\n",
    "            T_score=cv2.resize(char_gt_score,(img.shape[1],img.shape[0]))\n",
    "            L_score=cv2.resize(link_gt_score,(img.shape[1],img.shape[0]))\n",
    "\n",
    "            plt.imshow(T_score)\n",
    "            plt.show()\n",
    "\n",
    "            mask = cvt2HeatmapImg(T_score)\n",
    "            cv2.imwrite('check_iter/T_scoremask.jpg',mask)\n",
    "\n",
    "\n",
    "            T_score_mask=np.multiply(T_score,255/np.max(T_score))\n",
    "            T_score_mask=T_score_mask.astype('uint8')\n",
    "        #     T_score_mask=cv2.cvtColor(T_score_mask,cv2.COLOR_GRAY2BGR)\n",
    "        #     cv2.imwrite('T_score.jpg',T_score)\n",
    "            plt.imshow(L_score)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            img=cv2.imread('check_iter/src.jpg')\n",
    "            word_img=img.copy()\n",
    "            char_img=img.copy()\n",
    "\n",
    "            det, labels, mapper = getDetBoxes_core(T_score,L_score,0.7,0.4,0.4)\n",
    "            for d in det:\n",
    "                counter=np.array(d,dtype='int32')\n",
    "                cv2.drawContours(word_img,[counter],-1,(255,255,255),2)\n",
    "            cv2.imwrite('check_iter/word_imgout.jpg',word_img)\n",
    "\n",
    "            det, labels, mapper = getDetBoxes_core(T_score,L_score,0.7,10,0.4)\n",
    "            for d in det:\n",
    "                counter=np.array(d,dtype='int32')\n",
    "                cv2.drawContours(char_img,[counter],-1,(255,255,255),2)\n",
    "\n",
    "\n",
    "            char_img[:,:,2]=T_score_mask #np.multiply(char_img,0.7)+    np.multiply(T_score_mask,0.3) \n",
    "            cv2.imwrite('check_iter/char_imgout.jpg',char_img)\n",
    "\n",
    "            break\n",
    "            \n",
    "    def training(self):\n",
    "        assert(self.train)\n",
    "        step=0\n",
    "        train_loss=0\n",
    "        for epoch in range(self.epochos):\n",
    "            self._build_data()\n",
    "            \n",
    "            print('lr:',self.trainer.learning_rate)\n",
    "            \n",
    "            pbar = tqdm(range(len(self.data_iter)))\n",
    "            for i,batch_data in zip(pbar,self.data_iter):\n",
    "                batch_img=batch_data[0].as_in_context(mx.gpu())\n",
    "                batch_char_gt = batch_data[1].as_in_context(mx.gpu())\n",
    "                batch_link_gt = batch_data[2].as_in_context(mx.gpu())\n",
    "\n",
    "                with ag.record():\n",
    "                    out=self.net(batch_img)\n",
    "                    batch_char_pred=out[:,0,:,:]\n",
    "                    batch_link_pred=out[:,1,:,:]\n",
    "\n",
    "                    char_loss = self.loss_MSE(batch_char_pred,batch_char_gt)\n",
    "                    link_loss = self.loss_MSE(batch_link_pred,batch_link_gt)\n",
    "                    Loss = char_loss+ link_loss\n",
    "\n",
    "                Loss.backward()\n",
    "                self.trainer.step(self.batch)\n",
    "                step=step+1\n",
    "\n",
    "                train_loss += Loss.sum().asscalar()\n",
    "                pbar.set_description(f\"epo:{epoch},\")\n",
    "                \n",
    "                if step%1000==999:\n",
    "                    net.save_parameters('Models/result.params')\n",
    "\n",
    "            self.data_iter.__del__()\n",
    "        print(f\"epoch loss :{train_loss}\")\n",
    "        \n",
    "    def infer(self, Inputname='demo.jpg'):\n",
    "        \n",
    "        Max_w_h=2000\n",
    "\n",
    "\n",
    "        Out_img=Inputname.replace('.jpg','_out.jpg')\n",
    "        output_mask_name=Inputname.replace('.jpg','_outmask.jpg')\n",
    "        npimg=cv2.imread(Inputname)\n",
    "        r =  npimg.shape[0]/npimg.shape[1]\n",
    "        if max(npimg.shape)>Max_w_h and r>1:\n",
    "            npimg =cv2.resize(npimg,(int(Max_w_h*(1/r)),Max_w_h))\n",
    "        if max(npimg.shape)>Max_w_h and r<1:\n",
    "            npimg =cv2.resize(npimg,(Max_w_h,int(Max_w_h*r)))\n",
    "            \n",
    "            \n",
    "        w=int(npimg.shape[1]/16)\n",
    "        h=int(npimg.shape[0]/16)\n",
    "        src=cv2.resize(npimg,(w*16,h*16))\n",
    "        srccopy=src.copy()\n",
    "        \n",
    "        src = normalizeMeanVariance(src)\n",
    "        src=np.transpose(src,(2,0,1))\n",
    "        src=np.expand_dims(src,0)\n",
    "        mxnet_input=nd.array(src,ctx=self.ctx)\n",
    "        print(mxnet_input.shape)\n",
    "        out= self.net(mxnet_input).asnumpy()\n",
    "        \n",
    "        char_score=out[0][0]\n",
    "        link_score=out[0][1]\n",
    "\n",
    "        char_score=cv2.resize(char_score,(char_score.shape[1]*2,char_score.shape[0]*2))\n",
    "        img = cvt2HeatmapImg(char_score)\n",
    "        cv2.imwrite(output_mask_name,img)\n",
    "        plt.imshow(char_score)\n",
    "        plt.show()\n",
    "\n",
    "        img2 = srccopy.copy()\n",
    "        T_score=cv2.resize(char_score,(w*16,h*16))\n",
    "        L_score=cv2.resize(link_score,(w*16,h*16))\n",
    "        det, labels, mapper = getDetBoxes_core(T_score,L_score,0.7,0.4,0.4)\n",
    "\n",
    "\n",
    "\n",
    "        Countours=[]\n",
    "        print(len(det))\n",
    "        for d in det:\n",
    "            counter=np.array(d,dtype='int32')\n",
    "            cv2.drawContours(img2,[counter],-1,(0,0,255),2)\n",
    "            Countours.append(counter)\n",
    "        cv2.imwrite(Out_img,img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Det =Train_Char_Det(Synth_gt=None,ReCTS_root=\"/data3/fansen/CVProject/text-detection/DataSets/ReCTs/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c989aee75c416897e7d852db1e0d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6666.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-234ea062b797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7efaada3154c>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                     \u001b[0mbatch_char_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mbatch_link_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CVProject/text-detection/CharDet_mxnet/mxnet_CharDet.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;31m#         y = nd.transpose(y,(0,2,3,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/gluon/nn/conv_layers.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, weight, bias)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fwd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fwd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mConvolution\u001b[0;34m(data, weight, bias, kernel, stride, dilate, pad, num_filter, num_group, workspace, no_bias, cudnn_tune, cudnn_off, layout, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out, is_np_op)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mcreate_ndarray_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_np_ndarray_cls\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_np_op\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_ndarray_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Det.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
